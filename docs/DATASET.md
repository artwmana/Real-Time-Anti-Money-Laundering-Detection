# AMLNet Transaction Dataset (v1)

Synthetic Anti–Money-Laundering (AML) transaction dataset generated by the **AMLNet multi-agent simulation framework** (Zenodo: 10.5281/zenodo.16736515). This dataset is intended for AML research, fraud detection, risk modeling, and simulation of financial behavior.

---

## 1. Overview

AMLNet is a simulator of a financial ecosystem in which agents (customers, businesses, and money launderers) interact, producing realistic transaction patterns:

* **1,090,173** transactions
* **~4,927 customers**
* **~0.16%** marked as *money laundering*
* Labels are produced by the simulation engine and are guaranteed consistent
* Fully synthetic—safe for analysis and publication

---

## 2. File Structure

```
data/
├── raw/
│   └── AMLNet_August_2025.csv            # raw dataset exported from Zenodo
└── processed/
    ├── train.parquet
    ├── val.parquet
    └── test.parquet
docs/
├──dataset.yml                             # schema + preprocessing config
configs/
├──DATASET.md                              # documentation (this file)
```

---

## 3. Schema (Columns)

### Required Columns

| Column              | Type     | Description                       |
| ------------------- | -------- | --------------------------------- |
| step                | int64     | Simulation step (time index)      |
| type                | object | Payment method (TRANSFER, OSKO, BPAY, EFTPOS, DEBIT, NPP)                  |
| amount              | float64  | Transaction amount in Australian Dollar                |
| category            | object | 11 Transaction categories         |
| nameOrig            | object | Originating customer ID                     |
| nameDest            | object | Destination customer/merchant ID                    |
| oldbalanceOrg       | float64  | Account balance before transaction |
| newbalanceOrig      | float64  | Account balance after transaction  |
| isFraud             | int64     | Binary fraud indicator (0=legitimate, 1=fraudulent)                        |
| isMoneyLaundering   | int64     | Binary AML label (0=normal, 1=suspicious)             |
| laundering_typology | object | Specific money laundering pattern type                 |
| metadata            | object   | Additional metadata               |
| fraud_probability   | float64  | Calculated fraud risk score        |
| hour                | int64     | Hour of transaction               |
| day_of_week         | int64     | Day of week                       |
| day_of_month        | int64     | Day of month                      |
| month               | int64     | Month                             |

### Dtypes (post-processing)

| Column              | Dtype    |
| ------------------- | -------- |
| step                | int8     |
| type                | category |
| amount              | float64  |
| category            | category |
| nameOrig            | category |
| nameDest            | category |
| oldbalanceOrg       | float64  |
| newbalanceOrig      | float64  |
| isFraud             | bool     |
| isMoneyLaundering   | bool     |
| laundering_typology | category |
| metadata            | object   |
| fraud_probability   | float64  |
| hour                | int8     |
| day_of_week         | int8     |
| day_of_month        | int8     |
| month               | int8     |

### Metadata
In a dataset, metadata is json that contains:
```
├── timestamp (datetime)
├── location
│   ├── city (category)
│   ├── state (category)
│   ├── country (category)
│   └── postcode (int)
├── device_info
│   ├── type (category)
│   ├── os (category)
│   └── ip_address (str)
├── payment_method (category)
├── merchant_info
└── risk_indicators
    ├── amount_vs_average (float)
    ├── customer_risk_score (float)
    ├── category_risk (category)
    ├── risk_score (float)
    ├── unusual_time (bool)
    └── unusual_location (bool)
```

### Target

| Column              | Type   | Description                               |
| ------------------- | ------ | ----------------------------------------- |
| isFraud | bool | 1 — fraud, 0 — normal transaction |
| isMoneyLaundering | bool | 1 — suspicious/ML, 0 — normal transaction |
---

## 4. What does `notebooks/01_eda.ipynb` do

1. **Incremental loading.** Read the first 100k rows (`ROWS_TO_READ`), immediately convert temporary/categorical columns to compact types (`int16`, `category`, `bool`).
2. **Unpacking metadata.** Python-like strings are converted into dictionaries, after which expanded fields are added: `loc_*`, `device_*`, `merch_*`, `risk_*`, `payment_method`, `timestamp`. Numeric fields pass `pd.to_numeric`, string fields are filled with `Unknown`.
3. **Data quality.** `df.info(memory_usage='deep')`, top gaps, statistics on numerical columns and target imbalance.
4. **Features.** Added time sine/cosine signs, weekend indicators, balance deltas and ratios, custom/merchant/IP aggregates, risk-based indicators and categorical `customer_risk_bucket`.
5. **Visualizations.** Logarithmic distribution of amounts, barplot of ML shares by operation type, hourly profile (volume vs ML rate) and scatter `risk_score` vs target.
6. **User-level split.** `GroupShuffleSplit` by `nameOrig` (80/20) after discarding potential leaks (`timestamp`, `fraud_probability`). Statistics on size and target rate are displayed.
7. **Encoding pipeline.** `RobustScaler` for numeric ones, `OneHotEncoder` for columns with ≤8 categories, smoothed `SmoothedTargetEncoder` for high-cardinality features. The pipeline is trained only on train users.
8. **Insights.** The final markdown captures key conclusions and next steps (cost-sensitive loss, rolling windows, `nameOrig/nameDest` embeddings).

---

## 5. Feature Groups

### Numeric Features

* step, hour, day_of_week, day_of_month, month
* amount, oldbalanceOrg, newbalanceOrig, balance_delta, amt_to_balance
* risk_amount_vs_average, risk_customer_risk_score, risk_risk_score, risk_score_gap, amount_vs_avg_diff
* units: user_tx_count, user_amount_median, user_amount_std, user_unique_merchants, user_device_diversity, merchant_tx_count, amt_to_merchant_avg, ip_activity_rank

### Categorical Features

* type, category, payment_method, laundering_typology
* device_type, device_os
* loc_city, loc_state, loc_country, customer_risk_bucket
* high-cardinality ID: nameOrig, nameDest, merch_merchant_id, device_ip_address

---

## 6. Data Cleaning Rules

| Rule | Behavior |
| ------------------------ | -------- |
| Metadata anomalies | `normalize_python_json_string` → `ast.literal_eval` |
| Object NaNs | fill `Unknown` in loc/device/merchant/risk blocks |
| Invalid numerics | `pd.to_numeric(errors='coerce')` + median imputation |
| Ratio infinities | Replace with 0 after `replace([inf, -inf], nan)` and `fillna(0)` |

---

## 7. Encoding

- **Numeric** → `SimpleImputer(strategy='median')` → `RobustScaler`.
- **Low-card categoricals** (≤8 unique) → `SimpleImputer(most_frequent)` → `OneHotEncoder(handle_unknown='ignore')`.
- **High-card categoricals** → `SimpleImputer(most_frequent)` → `SmoothedTargetEncoder` with logistic smoothing (global average for unseen categories).
- All steps are combined into `ColumnTransformer`; encoder is trained only on train groups from user-based split.

---

## 8. Dataset Split Strategy

User-level `GroupShuffleSplit`:

* Train - 80%
* Test - 20%
* Group key - `nameOrig`

This approach eliminates the appearance of the same client in train and test, thereby preventing leaks in target encoding and models.

---

## 9. Typical ML Workflow

1. Loading + type optimization (as in 01_eda.ipynb)
2. Unpacking metadata, filling in gaps
3. Feature engineering (time, ratios, user/merchant/device units, risk-based)
4. User-based train/test split, fit encoding pipeline on train
5. Training models (CatBoost / LightGBM / tabular NN) with cost-sensitive metrics
6. Backtesting + drift monitoring and retraining if necessary

---

## 10. Citation

```
AMLNet Synthetic Dataset (2024). Zenodo. https://doi.org/10.5281/zenodo.16736515
```

---

## 11. License

The dataset is synthetic and freely available for research. See the Zenodo page for license details.
